{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWPnj-GknsDI"
      },
      "source": [
        "# Nutrition5k | Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJoAdONISoAE"
      },
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from random import seed, shuffle\n",
        "\n",
        "# Third-party library imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Typing imports\n",
        "from typing import Any, Dict, List, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iEnngTo294f"
      },
      "outputs": [],
      "source": [
        "# set the seed\n",
        "seed(2024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD31_zOLfMUR",
        "outputId": "af04b383-4585-4a3b-b2b0-a1d1a16f260e"
      },
      "outputs": [],
      "source": [
        "# check whether installed\n",
        "!gsutil --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhuWKeKpgqP3",
        "outputId": "cf630c0c-ee52-4244-e285-1c4c2ed3e75c"
      },
      "outputs": [],
      "source": [
        "# download dataset\n",
        "!mkdir -p nutrition5k_dataset/metadata\n",
        "!mkdir -p nutrition5k_dataset/dish_ids\n",
        "!mkdir -p nutrition5k_dataset/imagery/realsense_overhead\n",
        "!gsutil -m cp -r \"gs://nutrition5k_dataset/nutrition5k_dataset/dish_ids/dish_ids_all.txt\" ./nutrition5k_dataset/dish_ids/\n",
        "!gsutil -m cp -r \"gs://nutrition5k_dataset/nutrition5k_dataset/metadata/dish_metadata_cafe1.csv\" ./nutrition5k_dataset/metadata/\n",
        "!gsutil -m cp -r \"gs://nutrition5k_dataset/nutrition5k_dataset/imagery/realsense_overhead\" ./nutrition5k_dataset/imagery/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hz45p1WmH5HN",
        "outputId": "854d45fc-c25a-4de7-a6ba-b8dc06c77109"
      },
      "outputs": [],
      "source": [
        "!mkdir -p nutrition5k_dataset/dish_ids/splits\n",
        "!gsutil -m cp -r \"gs://nutrition5k_dataset/nutrition5k_dataset/dish_ids/splits/rgb_train_ids.txt\" ./nutrition5k_dataset/dish_ids/splits/\n",
        "!gsutil -m cp -r \"gs://nutrition5k_dataset/nutrition5k_dataset/dish_ids/splits/rgb_test_ids.txt\" ./nutrition5k_dataset/dish_ids/splits/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVNi3n4q2oYd",
        "outputId": "95bdd034-2002-41c2-8778-d08b0a8baef4"
      },
      "outputs": [],
      "source": [
        "# split original train set in train and validation subsplits\n",
        "with open(\"./nutrition5k_dataset/dish_ids/splits/rgb_train_ids.txt\") as fp:\n",
        "  train_ids = fp.read().split(\"\\n\")\n",
        "\n",
        "print(len(train_ids))\n",
        "cutoff = int(len(train_ids) * 0.8)\n",
        "shuffle(train_ids)\n",
        "\n",
        "with open(\"./nutrition5k_dataset/dish_ids/splits/rgb_test_ids.txt\") as fp:\n",
        "  test_ids = fp.read().split(\"\\n\")\n",
        "\n",
        "print(f\"Train/Train Split: {cutoff}, Train/Valid: Split: {len(train_ids)-cutoff}\")\n",
        "\n",
        "with open(\"./nutrition5k_dataset/dish_ids/splits/rgb_train_train_ids.txt\", \"w\") as fp:\n",
        "  for i, _id in enumerate(train_ids[:cutoff]):\n",
        "    if i < cutoff-1:\n",
        "      fp.write(f\"{_id}\\n\")\n",
        "    else:\n",
        "      fp.write(f\"{_id}\")\n",
        "\n",
        "with open(\"./nutrition5k_dataset/dish_ids/splits/rgb_train_val_ids.txt\", \"w\") as fp:\n",
        "  for i, _id in enumerate(train_ids[cutoff:]):\n",
        "    if i < cutoff-1:\n",
        "      fp.write(f\"{_id}\\n\")\n",
        "    else:\n",
        "      fp.write(f\"{_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxc60TIVRACF"
      },
      "outputs": [],
      "source": [
        "class N5kRealSense(Dataset):\n",
        "    def __init__(self, path_imagery, path_labels_csv, path_split_txt, transform=None, target_transform=None):\n",
        "        self.path_imagery = Path(path_imagery)\n",
        "        assert self.path_imagery.is_dir()\n",
        "\n",
        "        dish_id_to_image_path = {}\n",
        "        for path_dish in Path(path_imagery).glob(\"*\"):\n",
        "          dish_id = path_dish.name\n",
        "          path_img = Path(path_dish, \"rgb.png\")\n",
        "          assert path_img.is_file()\n",
        "          #print(path_img)\n",
        "          dish_id_to_image_path[dish_id] = str(path_img)\n",
        "        self.dish_id_to_image_path = dish_id_to_image_path\n",
        "\n",
        "        self.labels = pd.read_csv(path_labels_csv, usecols=range(6), header=None, index_col=0)\n",
        "\n",
        "        with open(path_split_txt, \"r\") as fp:\n",
        "          _split_ids = fp.read()\n",
        "        _split_ids = _split_ids.split(\"\\n\")\n",
        "        self.split_ids = []\n",
        "        for _split_id in _split_ids:\n",
        "          if _split_id in self.dish_id_to_image_path:\n",
        "            self.split_ids.append(_split_id)\n",
        "\n",
        "\n",
        "        print(f\"Split size: {len(self.split_ids)} (orginal: {len(_split_ids)})\")\n",
        "\n",
        "        #self.split_ids = pd.read_csv(path_split_txt, header=None, index_col=None)\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.split_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # get next dish id from split list\n",
        "        dish_id = self.split_ids[idx]\n",
        "        #print(dish_id)\n",
        "\n",
        "        # get image for this dish_id\n",
        "        path_image = self.dish_id_to_image_path[dish_id]\n",
        "        #assert path_image.is_file(), path_image\n",
        "        image = Image.open(path_image)\n",
        "        #image = image.convert(\"RGB\")\n",
        "\n",
        "        # get label for this dish_id\n",
        "        target = self.labels.loc[dish_id].to_numpy()\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        if self.target_transform:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMPsxJ0eUE6o",
        "outputId": "c9942528-6cc4-4a41-ad3f-70819e69a5cb"
      },
      "outputs": [],
      "source": [
        "# generate non-transformed train and validation sets\n",
        "\n",
        "train_set_no_transform = N5kRealSense(\n",
        "    path_imagery=\"./nutrition5k_dataset/imagery/realsense_overhead\",\n",
        "    path_labels_csv=\"./nutrition5k_dataset/metadata/dish_metadata_cafe1.csv\",\n",
        "    path_split_txt=\"./nutrition5k_dataset/dish_ids/splits/rgb_train_train_ids.txt\",\n",
        ")\n",
        "\n",
        "valid_set_no_transform = N5kRealSense(\n",
        "    path_imagery=\"./nutrition5k_dataset/imagery/realsense_overhead\",\n",
        "    path_labels_csv=\"./nutrition5k_dataset/metadata/dish_metadata_cafe1.csv\",\n",
        "    path_split_txt=\"./nutrition5k_dataset/dish_ids/splits/rgb_train_val_ids.txt\",\n",
        ")\n",
        "\n",
        "test_set_no_transform = N5kRealSense(\n",
        "    path_imagery=\"./nutrition5k_dataset/imagery/realsense_overhead\",\n",
        "    path_labels_csv=\"./nutrition5k_dataset/metadata/dish_metadata_cafe1.csv\",\n",
        "    path_split_txt=\"./nutrition5k_dataset/dish_ids/splits/rgb_test_ids.txt\",\n",
        ")\n",
        "\n",
        "# Example use\n",
        "# Choose a random sample index\n",
        "sample_idx = np.random.randint(0, len(train_set_no_transform))\n",
        "\n",
        "# Get the sample image and target label\n",
        "image, target = train_set_no_transform[sample_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArHid48ZX8pf",
        "outputId": "0d24c397-4499-46f1-bdae-b522bb3f0746"
      },
      "outputs": [],
      "source": [
        "def calculate_target_mean(dataset: N5kRealSense) -> Dict[int, float]:\n",
        "    \"\"\"\n",
        "    Calculate the mean across all target dimensions in the input dataset.\n",
        "    Returns a dictionary of the means.\n",
        "\n",
        "    Args:\n",
        "    - dataset (N5kRealSense): The dataset containing target values.\n",
        "\n",
        "    Returns:\n",
        "    - Dict[int, float]: A dictionary containing the mean across all target dimensions.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize an empty NumPy array to accumulate target values\n",
        "    target_sum = np.zeros_like(dataset[0][1], dtype=float)\n",
        "\n",
        "    # Iterate through the dataset to accumulate target values\n",
        "    for _, target in dataset:\n",
        "        target_sum += target\n",
        "\n",
        "    # Calculate the mean across all target dimensions\n",
        "    num_samples = len(dataset)\n",
        "    target_mean = {i: value / num_samples for i, value in enumerate(target_sum)}\n",
        "    target_mean = {\n",
        "            \"total_calories\": target_mean[0],\n",
        "            \"total_mass\": target_mean[1],\n",
        "            \"total_fat\": target_mean[2],\n",
        "            \"total_carb\": target_mean[3],\n",
        "            \"total_protein\": target_mean[4]}\n",
        "    return target_mean\n",
        "\n",
        "target_mean = calculate_target_mean(train_set_no_transform)\n",
        "target_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltoBF50LeJrK"
      },
      "outputs": [],
      "source": [
        "def get_target_values(val_set: N5kRealSense) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Helper function to derive the target values as a NumPy array from the validation set.\n",
        "\n",
        "    Args:\n",
        "    - val_set (N5kRealSense): The validation set of the N5kRealSense dataset.\n",
        "\n",
        "    Returns:\n",
        "    - np.ndarray: A NumPy array containing the target values from the validation set.\n",
        "    \"\"\"\n",
        "    # Initialize an empty list to store the target values\n",
        "    target_values = []\n",
        "\n",
        "    # Iterate through the validation set to extract target values\n",
        "    for _, target in val_set:\n",
        "        # Append the target values to the list\n",
        "        target_values.append(target)\n",
        "\n",
        "    # Convert the list of target values to a NumPy array\n",
        "    target_values_np = np.array(target_values)\n",
        "\n",
        "    return target_values_np\n",
        "\n",
        "df_test = get_target_values(test_set_no_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrctRAdtZr2C"
      },
      "outputs": [],
      "source": [
        "class MeanRegressionModel:\n",
        "    \"\"\"Create predictions based on the mean of the training dataset.\n",
        "    Mean function defined separately\"\"\"\n",
        "    def __init__(self, target_mean: Dict[int, float], val_set: Dataset):\n",
        "        self.target_mean = target_mean\n",
        "        self.val_set = val_set\n",
        "\n",
        "    def predict(self) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Predict target values for the validation set using the mean dictionary.\n",
        "\n",
        "        Returns:\n",
        "        - np.ndarray: Predicted target values for the validation set.\n",
        "        \"\"\"\n",
        "        # Extract the number of dimensions from the mean dictionary\n",
        "        num_dimensions = len(self.target_mean)\n",
        "\n",
        "        # Create predictions by repeating the mean values for each sample in the validation set\n",
        "        predictions = np.array([list(self.target_mean.values()) for _ in range(len(self.val_set))])\n",
        "\n",
        "        return predictions\n",
        "\n",
        "mean_regressor = MeanRegressionModel(target_mean, test_set_no_transform)\n",
        "df_mean_preds = mean_regressor.predict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "zv2PRJdpqtyD",
        "outputId": "ef915c70-443a-462c-a10f-fdf63094fb03"
      },
      "outputs": [],
      "source": [
        "def evaluate_single_output_function(true_values: np.ndarray, predicted_values: np.ndarray) -> Tuple[float, float, float]:\n",
        "    \"\"\"\n",
        "    Evaluate the performance of a single output regression model.\n",
        "\n",
        "    Args:\n",
        "    - true_values (np.ndarray): Ground truth target values.\n",
        "    - predicted_values (np.ndarray): Predicted target values.\n",
        "\n",
        "    Returns:\n",
        "    - Tuple[float, float, float]: MAE, MAPE, R2 scores.\n",
        "    \"\"\"\n",
        "    mae = mean_absolute_error(true_values, predicted_values)\n",
        "    mape = mean_absolute_percentage_error(true_values+0.1, predicted_values) # avoid division by zero\n",
        "    r2 = r2_score(true_values, predicted_values)\n",
        "    return mae, mape, r2\n",
        "\n",
        "def calculate_metrics(target_dims: List[str], true_values: np.ndarray, predicted_values: np.ndarray) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculate metrics for each target dimension.\n",
        "\n",
        "    Args:\n",
        "    - target_dims (List[str]): List of target dimensions.\n",
        "    - true_values (np.ndarray): NumPy array containing true target values.\n",
        "    - predicted_values (np.ndarray): NumPy array containing predicted target values.\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: DataFrame containing calculated metrics.\n",
        "    \"\"\"\n",
        "    metrics_dict = {\"dimension\": [], \"MAE\": [], \"MAPE\": [], \"R2\": []}\n",
        "\n",
        "    for dim in target_dims:\n",
        "        # Translate dimension into index\n",
        "        dim_index = {\"cal\": 0, \"mass\": 1, \"protein\": 2, \"carb\": 3, \"fat\": 4}[dim]\n",
        "\n",
        "        true_values_dim = true_values[:, dim_index]\n",
        "        predicted_values_dim = predicted_values[:, dim_index]\n",
        "\n",
        "        mae, mape, r2 = evaluate_single_output_function(true_values_dim, predicted_values_dim)\n",
        "        metrics_dict[\"dimension\"].append(dim)\n",
        "        metrics_dict[\"MAE\"].append(mae)\n",
        "        metrics_dict[\"MAPE\"].append(mape)\n",
        "        metrics_dict[\"R2\"].append(r2)\n",
        "\n",
        "    metrics_df = pd.DataFrame(metrics_dict).transpose()\n",
        "    metrics_df = metrics_df.iloc[1:4]\n",
        "    metrics_df.columns = target_dims\n",
        "\n",
        "    return metrics_df\n",
        "\n",
        "# Evaluation of simple baseline model:\n",
        "target_dims = np.array([\"cal\", \"protein\", \"carb\", \"fat\"])\n",
        "metrics_df = calculate_metrics(target_dims, df_test, df_mean_preds)\n",
        "metrics_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9goJXacAwrT"
      },
      "outputs": [],
      "source": [
        "# Load predictions of vision transformer\n",
        "df_vit_preds = np.load('best-outputs2.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "CWpbjcM20UBf",
        "outputId": "31278515-7e58-4119-9f19-96a5cd44e6ab"
      },
      "outputs": [],
      "source": [
        "# Evaluation of ViT\n",
        "target_dims = np.array([\"cal\", \"protein\", \"carb\", \"fat\"])\n",
        "metrics_vit_df = calculate_metrics(target_dims, df_test, df_vit_preds)\n",
        "metrics_vit_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gip55OkhA8Bx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
