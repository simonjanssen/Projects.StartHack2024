{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wFhiSA5DCvQ"
      },
      "source": [
        "# Nutrition5k | Data Preparation and Training\n",
        "\n",
        "Dataset: [https://github.com/google-research-datasets/Nutrition5k](https://github.com/google-research-datasets/Nutrition5k)\n",
        "\n",
        "Paper: [https://arxiv.org/abs/2103.03375](https://arxiv.org/abs/2103.03375)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Napa8Rg27m-P"
      },
      "outputs": [],
      "source": [
        "!pip install timm loguru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iEnngTo294f"
      },
      "outputs": [],
      "source": [
        "# import modules\n",
        "import torch\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import SGD, Adam\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from timm import create_model\n",
        "from timm.utils.model import get_state_dict, unwrap_model\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "from random import seed, shuffle\n",
        "seed(2024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD31_zOLfMUR",
        "outputId": "a0823d42-1293-4f43-b66a-4f583b5d4df9"
      },
      "outputs": [],
      "source": [
        "# check whether installed\n",
        "!gsutil --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhuWKeKpgqP3"
      },
      "outputs": [],
      "source": [
        "# download annotation data\n",
        "!mkdir -p nutrition5k_dataset/metadata\n",
        "!gsutil -m cp -r \"gs://nutrition5k_dataset/nutrition5k_dataset/metadata/dish_metadata_cafe1.csv\" ./nutrition5k_dataset/metadata/\n",
        "!mkdir -p nutrition5k_dataset/dish_ids/splits\n",
        "!gsutil -m cp -r \"gs://nutrition5k_dataset/nutrition5k_dataset/dish_ids/dish_ids_all.txt\" ./nutrition5k_dataset/dish_ids/\n",
        "!gsutil -m cp -r \"gs://nutrition5k_dataset/nutrition5k_dataset/dish_ids/splits/rgb_train_ids.txt\" ./nutrition5k_dataset/dish_ids/splits/\n",
        "!gsutil -m cp -r \"gs://nutrition5k_dataset/nutrition5k_dataset/dish_ids/splits/rgb_test_ids.txt\" ./nutrition5k_dataset/dish_ids/splits/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZLWA8yfb3JN",
        "outputId": "cbba2efa-15c1-4be2-a0d7-b660e04bf883"
      },
      "outputs": [],
      "source": [
        "# split original train set in train and validation subsplits\n",
        "with open(\"./nutrition5k_dataset/dish_ids/splits/rgb_train_ids.txt\") as fp:\n",
        "  train_ids = fp.read().split(\"\\n\")\n",
        "\n",
        "print(len(train_ids))\n",
        "cutoff = int(len(train_ids) * 0.8)\n",
        "shuffle(train_ids)\n",
        "\n",
        "print(f\"Train/Train Split: {cutoff}, Train/Valid: Split: {len(train_ids)-cutoff}\")\n",
        "\n",
        "with open(\"./nutrition5k_dataset/dish_ids/splits/rgb_train_train_ids.txt\", \"w\") as fp:\n",
        "  for i, _id in enumerate(train_ids[:cutoff]):\n",
        "    if i < cutoff-1:\n",
        "      fp.write(f\"{_id}\\n\")\n",
        "    else:\n",
        "      fp.write(f\"{_id}\")\n",
        "\n",
        "with open(\"./nutrition5k_dataset/dish_ids/splits/rgb_train_val_ids.txt\", \"w\") as fp:\n",
        "  for i, _id in enumerate(train_ids[cutoff:]):\n",
        "    if i < cutoff-1:\n",
        "      fp.write(f\"{_id}\\n\")\n",
        "    else:\n",
        "      fp.write(f\"{_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZWwgoKnblif"
      },
      "outputs": [],
      "source": [
        "# download image data\n",
        "!mkdir -p nutrition5k_dataset/imagery/realsense_overhead\n",
        "!gsutil -m cp -r \"gs://nutrition5k_dataset/nutrition5k_dataset/imagery/realsense_overhead\" ./nutrition5k_dataset/imagery/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyBt_utlZhTd"
      },
      "outputs": [],
      "source": [
        "# pytorch data classes / custom transforms\n",
        "class N5kRealSense(Dataset):\n",
        "    def __init__(self, path_imagery, path_labels_csv, path_split_txt, transform=None, target_transform=None):\n",
        "        self.path_imagery = Path(path_imagery)\n",
        "        assert self.path_imagery.is_dir()\n",
        "\n",
        "        dish_id_to_image_path = {}\n",
        "        for path_dish in Path(path_imagery).glob(\"*\"):\n",
        "          dish_id = path_dish.name\n",
        "          path_img = Path(path_dish, \"rgb.png\")\n",
        "          assert path_img.is_file(), path_img\n",
        "          dish_id_to_image_path[dish_id] = str(path_img)\n",
        "        self.dish_id_to_image_path = dish_id_to_image_path\n",
        "\n",
        "        self.labels = pd.read_csv(path_labels_csv, usecols=range(6), header=None, index_col=0)\n",
        "\n",
        "        with open(path_split_txt, \"r\") as fp:\n",
        "          _split_ids = fp.read()\n",
        "        _split_ids = _split_ids.split(\"\\n\")\n",
        "        self.split_ids = []\n",
        "        for _split_id in _split_ids:\n",
        "          if _split_id in self.dish_id_to_image_path:\n",
        "            self.split_ids.append(_split_id)\n",
        "\n",
        "        print(f\"Split size: {len(self.split_ids)} (orginal: {len(_split_ids)})\")\n",
        "\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.split_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # get next dish id from split list\n",
        "        dish_id = self.split_ids[idx]\n",
        "\n",
        "        # get image for this dish_id\n",
        "        path_image = self.dish_id_to_image_path[dish_id]\n",
        "        image = Image.open(path_image)\n",
        "\n",
        "        # get label for this dish_id\n",
        "        target = self.labels.loc[dish_id].to_numpy()\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        if self.target_transform:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return image, target\n",
        "\n",
        "\n",
        "class NumpyToTensor(object):\n",
        "    \"\"\"Convert a numpy.ndarray to a tensor.\"\"\"\n",
        "\n",
        "    def __call__(self, np_array):\n",
        "        return torch.from_numpy(np_array).unsqueeze(0)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '()'\n",
        "\n",
        "\n",
        "class StandardizeTensor(object):\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "\n",
        "        if not torch.is_tensor(tensor):\n",
        "            raise TypeError('Input tensor should be a torch tensor. Got {}.'.format(type(tensor)))\n",
        "        \n",
        "        mean = torch.tensor(self.mean).reshape(1, 1, -1)\n",
        "        std = torch.tensor(self.std).reshape(1, 1, -1)\n",
        "        standardized_vectors = (tensor - mean) / std\n",
        "        return standardized_vectors.squeeze(1)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
        "\n",
        "\n",
        "def de_transform(x, mean=[255, 215, 12.7, 19.4, 18.0], std=[220, 161, 13.5, 21.6, 20]):\n",
        "    mean = np.array(mean)\n",
        "    std = np.array(std)\n",
        "    x_ = (x * std) + mean\n",
        "    return x_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjsRcWfGZ7VB",
        "outputId": "b74b83fc-f5f3-4f0c-e9f5-1842ef2cef81"
      },
      "outputs": [],
      "source": [
        "# prepare for data loaders\n",
        "input_transform_train = transforms.Compose([\n",
        "    transforms.Resize(255),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    transforms.ColorJitter(hue=0.05),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.GaussianBlur(kernel_size=(5,5), sigma=(0.01, 0.3))\n",
        "])\n",
        "\n",
        "input_transform_valid = transforms.Compose([\n",
        "    transforms.Resize(255),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# total_calories, total_mass, total_fat, total_carb, total_protein\n",
        "# as stated in the paper\n",
        "mean_paper = [255, 215, 12.7, 19.4, 18.0]\n",
        "std_paper = [220, 161, 13.5, 21.6, 20]\n",
        "target_transform = transforms.Compose([\n",
        "    NumpyToTensor(),\n",
        "    StandardizeTensor(mean=mean_paper, std=std_paper)\n",
        "])\n",
        "\n",
        "train_set = N5kRealSense(\n",
        "    path_imagery=\"./nutrition5k_dataset/imagery/realsense_overhead\",\n",
        "    path_labels_csv=\"./nutrition5k_dataset/metadata/dish_metadata_cafe1.csv\",\n",
        "    path_split_txt=\"./nutrition5k_dataset/dish_ids/splits/rgb_train_train_ids.txt\",\n",
        "    transform=input_transform_train,\n",
        "    target_transform=target_transform\n",
        ")\n",
        "\n",
        "valid_set = N5kRealSense(\n",
        "    path_imagery=\"./nutrition5k_dataset/imagery/realsense_overhead\",\n",
        "    path_labels_csv=\"./nutrition5k_dataset/metadata/dish_metadata_cafe1.csv\",\n",
        "    path_split_txt=\"./nutrition5k_dataset/dish_ids/splits/rgb_train_val_ids.txt\",\n",
        "    transform=input_transform_valid,\n",
        "    target_transform=target_transform\n",
        ")\n",
        "\n",
        "test_set = N5kRealSense(\n",
        "    path_imagery=\"./nutrition5k_dataset/imagery/realsense_overhead\",\n",
        "    path_labels_csv=\"./nutrition5k_dataset/metadata/dish_metadata_cafe1.csv\",\n",
        "    path_split_txt=\"./nutrition5k_dataset/dish_ids/splits/rgb_test_ids.txt\",\n",
        "    transform=input_transform_valid,\n",
        "    target_transform=target_transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_set,\n",
        "    batch_size=32,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "valid_loader = DataLoader(\n",
        "    valid_set,\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_set,\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-u4XkUddzHb"
      },
      "outputs": [],
      "source": [
        "# init model\n",
        "model_name = \"tiny_vit_5m_224\"  # good modern vision transformer, others: efficientnet_b0, paper baseline: inception_resnet_v2\n",
        "custom = False\n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.backbone = backbone\n",
        "        self.fc1 = nn.Linear(320, 32)\n",
        "        self.fc2 = nn.Linear(32, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "if custom:\n",
        "  backbone = create_model(model_name, pretrained=True, num_classes=0)  # https://huggingface.co/docs/timm/feature_extraction\n",
        "  model = CustomModel(backbone)\n",
        "else:\n",
        "  model = create_model(model_name, pretrained=True, num_classes=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5aNBYoGZ05s",
        "outputId": "0f52959b-b451-40b5-f196-168032993709"
      },
      "outputs": [],
      "source": [
        "# train model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model.to(device)\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.L1Loss()  # nn.MSELoss()\n",
        "\n",
        "def train_one_epoch(model, loader):\n",
        "  model.train()\n",
        "  loss_acc = 0\n",
        "  pbar = tqdm(loader, total=len(loader))\n",
        "  n_samples = 0\n",
        "  for input, target in pbar:\n",
        "    n_samples += input.size(0)\n",
        "    input = input.float().to(device)\n",
        "    target = target.float().to(device)\n",
        "    output = model(input).unsqueeze(0).permute(1, 0, 2)\n",
        "    loss = loss_fn(output, target)\n",
        "    loss_acc += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    loss_avg = loss_acc / n_samples\n",
        "    pbar.set_description(f'Train Loss: {loss_avg:.06f}')\n",
        "\n",
        "  return loss_avg\n",
        "\n",
        "def valid_one_epoch(model, loader):\n",
        "  model.eval()\n",
        "  loss_acc = 0\n",
        "  with torch.no_grad():\n",
        "    pbar = tqdm(loader, total=len(loader))\n",
        "    n_samples = 0\n",
        "    for input, target in pbar:\n",
        "      n_samples += input.size(0)\n",
        "      input = input.float().to(device)\n",
        "      target = target.float().to(device)\n",
        "      output = model(input).unsqueeze(0).permute(1, 0, 2)\n",
        "      loss = loss_fn(output, target)\n",
        "      loss_acc += loss.item()\n",
        "      loss_avg = loss_acc / n_samples\n",
        "      pbar.set_description(f'Valid Loss: {loss_avg:.06f}')\n",
        "\n",
        "  return loss_avg\n",
        "\n",
        "epochs = 15\n",
        "best_valid_loss_avg = np.inf\n",
        "ts = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
        "for e in range(epochs):\n",
        "  print(f\"\\n\\n{e}/{epochs}\")\n",
        "  train_loss_avg = train_one_epoch(model, train_loader)\n",
        "  valid_loss_avg = valid_one_epoch(model, valid_loader)\n",
        "  print(f\"\\nTrain/Valid Loss: {train_loss_avg:.06f}/{valid_loss_avg:.06f}\")\n",
        "  if valid_loss_avg < best_valid_loss_avg:\n",
        "    best_model = model\n",
        "    best_valid_loss_avg = valid_loss_avg\n",
        "    path_save = Path(f\"./runs/{ts}-{model_name}/best-{e:03d}.pth\")\n",
        "    path_save.parent.mkdir(exist_ok=True, parents=True)\n",
        "    save_state = get_state_dict(model, unwrap_model)\n",
        "    torch.save(save_state, path_save)\n",
        "  with open(Path(path_save.parent, \"logs.csv\"), \"a\") as fp:\n",
        "    fp.write(f\"{e},{train_loss_avg},{valid_loss_avg}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KLJpAIARhlr",
        "outputId": "98fc35b6-c9f4-42ae-eb54-8b1c5fe9ebc4"
      },
      "outputs": [],
      "source": [
        "# re-create model from checkpoint\n",
        "def load_model(path_checkpoint, CustomModelClass=None):\n",
        "  base_model = create_model(\"tiny_vit_5m_224\", in_chans=3, num_classes=5, checkpoint_path=path_checkpoint)\n",
        "  if CustomModelClass:\n",
        "    custom_model = CustomModelClass(model)\n",
        "    state_dict = torch.load(path_checkpoint)\n",
        "    custom_model.load_state_dict(state_dict)\n",
        "    return custom_model\n",
        "  else:\n",
        "    return base_model\n",
        "\n",
        "# execute model in inference mode\n",
        "def run_inference(model, loader):\n",
        "  model.eval()\n",
        "  loss_acc = 0\n",
        "  n_samples = len(loader.dataset)\n",
        "  targets = torch.empty((n_samples, 1, 5), device=device)\n",
        "  outputs = torch.empty((n_samples, 1, 5), device=device)\n",
        "  with torch.no_grad():\n",
        "    pbar = tqdm(loader, total=len(loader))\n",
        "    n_samples = 0\n",
        "    n_end = 0\n",
        "    for input, target in pbar:\n",
        "      n_start = n_end\n",
        "      n_end = n_start + input.size(0)\n",
        "      input = input.float().to(device)\n",
        "      output = model(input).unsqueeze(0).permute(1, 0, 2)\n",
        "      target = target.float()\n",
        "\n",
        "      # store results\n",
        "      outputs[n_start:n_end,:,:] = output.detach()\n",
        "      targets[n_start:n_end,:,:] = target.detach()\n",
        "\n",
        "  return outputs.cpu().numpy(), targets.cpu().numpy()\n",
        "\n",
        "# load model\n",
        "model_from_checkpoint = load_model(\"/content/runs/20240321-231807-tiny_vit_5m_224/best-013.pth\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_from_checkpoint.to(device)\n",
        "\n",
        "# evaluate model\n",
        "test_loss_avg = valid_one_epoch(model_from_checkpoint, test_loader)\n",
        "\n",
        "# generate inference results\n",
        "outputs, targets = run_inference(model_from_checkpoint, test_loader)\n",
        "\n",
        "# de-normalize outputs\n",
        "outputs_transformed = de_transform(outputs).squeeze()\n",
        "targets_transformed = de_transform(targets).squeeze()\n",
        "print(outputs.shape, targets.shape)\n",
        "\n",
        "# save results\n",
        "with open(Path(path_save.parent, \"best-outputs.npy\"), \"wb\") as fp:\n",
        "  np.save(fp, outputs_transformed)\n",
        "\n",
        "with open(Path(path_save.parent, \"best-targets.npy\"), \"wb\") as fp:\n",
        "  np.save(fp, targets_transformed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xj0SMO_6psCa",
        "outputId": "23bde9bd-7be5-42c6-b80d-76d43e69c872"
      },
      "outputs": [],
      "source": [
        "# verify npy files\n",
        "with open(Path(path_save.parent, \"best-outputs.npy\"), \"rb\") as fp:\n",
        "  _outputs = np.load(fp)\n",
        "  print(_outputs.shape)\n",
        "\n",
        "with open(Path(path_save.parent, \"best-targets.npy\"), \"rb\") as fp:\n",
        "  _targets = np.load(fp)\n",
        "  print(_targets.shape)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
